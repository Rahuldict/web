{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881a14ef-f327-4b28-8829-3a40590356c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b538de6-4913-4cf0-b3ad-81c63acb1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Web scraping is the process of automatically extracting information and data from websites. It involves using code (usually in programming languages like Python) to retrieve specific pieces of data from web pages. Web scraping is used to gather data that might not be easily accessible through APIs or other structured methods. It's commonly used for tasks such as data collection, market research, competitive analysis, and more.\n",
    "\n",
    "Three areas where web scraping is often used to gather data are:\n",
    "\n",
    "Business Intelligence and Market Research: Companies use web scraping to monitor competitors, track pricing information, and gather data on market trends. This helps them make informed decisions about their products and services.\n",
    "\n",
    "Content Aggregation: Websites and apps that aggregate news, articles, product listings, or other content from various sources often use web scraping to automatically pull in data from different websites.\n",
    "\n",
    "Academic Research: Researchers might use web scraping to collect data for academic purposes, such as analyzing social media trends, studying online discussions, or tracking changes in websites over time.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120cdbce-44e7-411c-b6e5-4edbb912c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03c6c0-25c7-4c4c-9140-51f4de5220c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Manual Copy-Paste: This involves manually copying and pasting data from web pages to a local file or database.\n",
    "\n",
    "Regular Expressions: Using regex, you can search for patterns in the raw HTML code to extract specific data. However, this can become complex and brittle if the website's structure changes.\n",
    "\n",
    "DOM Parsing: This involves using libraries like Beautiful Soup to parse the HTML or XML structure of a web page and extract specific elements.\n",
    "\n",
    "Headless Browsers: Tools like Selenium allow you to automate interactions with websites, including filling out forms and clicking buttons, which can be useful for scraping dynamically generated content.\n",
    "\n",
    "APIs: If a website provides an API (Application Programming Interface), you can use it to retrieve data in a structured format, avoiding the need for traditional scraping.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b394c1f-1ba2-4896-b91c-5d065f43d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49260ff-f294-4544-bf6d-c262201239e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Beautiful Soup is a Python library that provides tools for parsing HTML and XML documents. It creates a parse tree from the page's source code, which can then be traversed to extract specific data. Beautiful Soup helps with tasks like searching for specific HTML elements, navigating through the document's structure, and extracting data attributes.\n",
    "\n",
    "It's used in web scraping projects because it simplifies the process of extracting data from HTML documents. It handles parsing complexities, such as poorly formatted HTML, and provides a Pythonic way to interact with web page elements, making it a popular choice for scraping tasks.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c8910d-32d1-494e-8a40-e66378f47fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906fd90-e3ab-4f78-af57-ada88485989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Flask is a lightweight web framework for Python. It's often used for building web applications and APIs. In the context of a web scraping project, Flask might be used to create a user interface that allows users to input URLs or parameters for the scraping process. The scraped data could be displayed on a web page served by Flask.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584832d4-90d4-4fd9-b139-f2327097c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d502bc-43b6-41ed-8b64-05e18278ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Unfortunately, you haven't provided information about the specific AWS services used in your project. Please provide the names of the AWS services you're referring to, and I'd be happy to explain their uses'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
